{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7Da7ueYLyvQG"},"outputs":[],"source":["# =========================================================\n","# 0. Imports e Configuração\n","# =========================================================\n","import os\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from datasets import load_dataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","\n","# Criar pasta de gráficos\n","os.makedirs(\"graficos\", exist_ok=True)\n","\n","# Fixar semente global\n","RANDOM_STATE = 42\n","np.random.seed(RANDOM_STATE)\n","\n","# =========================================================\n","# 1. Dataset\n","# =========================================================\n","dataset = load_dataset(\"sms_spam\", split=\"train\")\n","df = pd.DataFrame(dataset)\n","df = df.rename(columns={\"sms\": \"texto\", \"label\": \"label\"})\n","\n","# =========================================================\n","# 2. Separação treino/teste\n","# =========================================================\n","X_train, X_test, y_train, y_test = train_test_split(\n","    df[\"texto\"], df[\"label\"], test_size=0.2, random_state=RANDOM_STATE, stratify=df[\"label\"]\n",")\n","\n","# =========================================================\n","# 3. Vetorização BOW e TF-IDF\n","# =========================================================\n","bow = CountVectorizer()\n","tfidf = TfidfVectorizer()\n","\n","X_train_bow = bow.fit_transform(X_train)\n","X_test_bow = bow.transform(X_test)\n","\n","X_train_tfidf = tfidf.fit_transform(X_train)\n","X_test_tfidf = tfidf.transform(X_test)\n","\n","# =========================================================\n","# 4. Treinamento do modelo\n","# =========================================================\n","model = LogisticRegression(max_iter=500, random_state=RANDOM_STATE)\n","model.fit(X_train_tfidf, y_train)\n","y_pred = model.predict(X_test_tfidf)\n","\n","print(\"[CLASSIFICAÇÃO TABULAR]\")\n","print(classification_report(y_test, y_pred))\n","\n","# =========================================================\n","# 5. Gráficos BOW e TF-IDF (determinísticos)\n","# =========================================================\n","\n","# Função auxiliar para pegar top K de forma determinística\n","def top_k_indices(arr, k=20):\n","    indices = np.argsort(arr)[::-1][:k]\n","    return indices\n","\n","# BOW\n","bow_sum = X_train_bow.sum(axis=0).A1\n","indices = top_k_indices(bow_sum, 20)\n","words = np.array(bow.get_feature_names_out())[indices]\n","freqs = bow_sum[indices]\n","\n","plt.figure(figsize=(8,6))\n","plt.barh(words, freqs)\n","plt.gca().invert_yaxis()  # colocar maior no topo\n","plt.title(\"Top 20 palavras - BOW (determinístico)\")\n","plt.tight_layout()\n","plt.savefig(\"graficos/bow_top20.png\", dpi=300)\n","plt.close()\n","\n","# TF-IDF\n","tfidf_sum = X_train_tfidf.sum(axis=0).A1\n","indices = top_k_indices(tfidf_sum, 20)\n","words = np.array(tfidf.get_feature_names_out())[indices]\n","scores = tfidf_sum[indices]\n","\n","plt.figure(figsize=(8,6))\n","plt.barh(words, scores)\n","plt.gca().invert_yaxis()\n","plt.title(\"Top 20 palavras - TF-IDF (determinístico)\")\n","plt.tight_layout()\n","plt.savefig(\"graficos/tfidf_top20.png\", dpi=300)\n","plt.close()\n","\n","print(\"Gráficos BOW e TF-IDF salvos em /graficos\")"]}]}